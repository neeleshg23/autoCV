%----------------------------------------------------------------------------------------
%	DOCUMENT DEFINITION
%----------------------------------------------------------------------------------------

% article class because we want to fully customize the page and not use a cv template
\documentclass[a4paper,12pt]{article}

%----------------------------------------------------------------------------------------
%	FONT
%----------------------------------------------------------------------------------------

% % fontspec allows you to use TTF/OTF fonts directly
% \usepackage{fontspec}
% \defaultfontfeatures{Ligatures=TeX}
% % modified for ShareLaTeX use
% \setmainfont[
% SmallCapsFont = Fontin-SmallCaps.otf,
% BoldFont = Fontin-Bold.otf,
% ItalicFont = Fontin-Italic.otf
% ]
% {Fontin.otf}

%----------------------------------------------------------------------------------------
%	PACKAGES
%----------------------------------------------------------------------------------------
\usepackage{url}
\usepackage{parskip}

%other packages for formatting
\RequirePackage{color}
\RequirePackage{graphicx}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[scale=0.9]{geometry}

%tabularx environment
\usepackage{tabularx}

%for lists within experience section
\usepackage{enumitem}

% centered version of 'X' col. type
\newcolumntype{C}{>{\centering\arraybackslash}X}

%to prevent spillover of tabular into next pages
\usepackage{supertabular}
\usepackage{tabularx}
\newlength{\fullcollw}
\setlength{\fullcollw}{0.47\textwidth}

%custom \section
\usepackage{titlesec}
\usepackage{multicol}
\usepackage{multirow}

%CV Sections inspired by:
%http://stefano.italians.nl/archives/26
\titleformat{\section}{\Large\scshape\raggedright}{}{0em}{}[\titlerule]
\titlespacing{\section}{0pt}{10pt}{10pt}

%for publications
\usepackage[sorting=ydnt, maxbibnames=10]{biblatex}

%Setup hyperref package, and colours for links
\usepackage[unicode, draft=false]{hyperref}
\definecolor{linkcolour}{rgb}{0,0.2,0.6}
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour,linkcolor=linkcolour}
\addbibresource{citations.bib}
\setlength\bibitemsep{1em}

%for social icons
\usepackage{fontawesome5}

%debug page outer frames
%\usepackage{showframe}

%----------------------------------------------------------------------------------------
%	BEGIN DOCUMENT
%----------------------------------------------------------------------------------------
\begin{document}

% non-numbered pages
\pagestyle{empty}

%----------------------------------------------------------------------------------------
%	TITLE
%----------------------------------------------------------------------------------------

% \begin{tabularx}{\linewidth}{ @{}X X@{} }
% \huge{Your Name}\vspace{2pt} & \hfill \emoji{incoming-envelope} email@email.com \\
% \raisebox{-0.05\height}\faGithub\ username \ | \
% \raisebox{-0.00\height}\faLinkedin\ username \ | \ \raisebox{-0.05\height}\faGlobe \ mysite.com  & \hfill \emoji{calling} number
% \end{tabularx}

\begin{tabularx}{\linewidth}{@{} C @{}}
\Huge{NEELESH GUPTA} \\[5.5pt]
\href{https://linkedin.com/in/neelesh-gupta23}{\raisebox{-0.05\height}\faLinkedin\ neelesh-gupta23} \ $|$ \
\href{https://neeleshg23.github.io/}{\raisebox{-0.05\height}\faGithub \ neeleshg23.github.io} \ $|$ \
\href{mailto:neeleshg@usc.edu}{\raisebox{-0.05\height}\faEnvelope \ neeleshg@usc.edu} \ $|$ \
\href{tel:+18325918299}{\raisebox{-0.05\height}\faMobile \ +1 (832) 591 8299} \\
\end{tabularx}

% \section{Summary}
% % I'm an incoming USC Computer Engineering PhD student with a background in applying ML for data prefetching and NN acceleration.  My current work focuses on reducing computations by predicting a model's hidden state early, and my broader research interests are in efficient computing for State Space Models and Edge LLMs, with a specific focus on applying hardware/software co-design for LLMs at the edge.
% I'm an incoming USC Computer Engineering PhD student with a background in applying ML for data prefetching and NN acceleration. My current work focuses on reducing computations by predicting a model's hidden state early.  My broader research interests are in edge computing, specifically targeting State Space Models and LLMs, with a strong interest in hardware/software co-design solutions.
% \section{Publications}
% \nocite{*}
% \printbibliography[heading=none]

%----------------------------------------------------------------------------------------
% EXPERIENCE SECTIONS
%----------------------------------------------------------------------------------------


% \begin{tabularx}{\linewidth}{ @{}l r@{} }
% \textbf{Lendly - Trade, Lend, Wear, Share} & \hfill \href{https://neeleshg23.github.io/2023/04/28/Lendly.html}{Link to Codebase} \\
% \multicolumn{2}{@{}X@{}}{
% \begin{minipage}[t]{\linewidth}
%     \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
%         \item[--] Engineered a high-performance, multithreaded REST API utilizing Spring Boot and Maven, while conducting validation of the backend using Postman to ensure robust functionality and reliability.
%         \item[--] Developed a responsive React frontend with CSS, leveraging Node.js for package management, utilizing hooks for state persistence and data refreshing, and seamlessly managing CORS with a backend proxy.
%         \item[--] Implemented streamlined deployment, auto-scaling, and reliable data storage using Google Cloud App Engine, Google Cloud SQL, and a GitHub Actions pipeline for continuous integration and deployment.
%     \end{itemize}
% \end{minipage}
% }
% \vspace{-1em}
% \\ \textbf{Handwritten Digit Recognizer} & \hfill \href{https://neeleshg23.github.io/tfjs.html}{Link to Demo} \\
% \multicolumn{2}{@{}X@{}}{
% \begin{minipage}[t]{\linewidth}
%     \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
%         \item[--] Developed a high-accuracy machine learning system for handwritten digit recognition using Python, TensorFlow, Keras, and a 2D Convolutional Neural Network architecture trained on GPGPU platform.
%         \item[--] Utilized TensorFlow.js, GitHub Pages, and Jekyll to successfully deploy a machine learning model, enabling the recognition of handwritten digits through an HTML frontend interface.
%     \end{itemize}
% \end{minipage}
% }
% \\
% \end{tabularx}
%----------------------------------------------------------------------------------------
%	EDUCATION
%----------------------------------------------------------------------------------------

\section{Education}
{\bf University of Southern California} \hfill {\bf Los Angeles, CA}
\\ {\em Ph.D. Computer Engineering} \hfill {\em August 2025 - December 2028}
\\
% {\bf University of Southern California} \hfill {\bf Los Angeles, CA}
% \\ {\em M.S. Computer Science} \hfill {\em August 2024 - December 2025}
% % \\
% \\
{\bf University of Southern California} \hfill {\bf Los Angeles, CA}
\\ {\em B.S. Computer Science, Minor: Mathematics} \hfill {\em August 2021 - May 2025}
%	SKILLS
\section{Skills}
\begin{tabularx}{\linewidth}{@{}l X@{}}
Programming Languages: & \normalsize{Python, C++, Verilog, Java} \\
Machine Learning: & \normalsize{PyTorch, HuggingFace, Llama.cpp, Triton, NetworkX} \\
Parallel Computing \& Hardware: & \normalsize{CUDA, OpenMP, MPI, SYCL, Vivado, ModelSim} \\
Tools \& Platforms: & \normalsize{Linux, Bash, Git, LaTeX, Jupyter Notebooks}\\
\end{tabularx}
% Interests/ Keywords/ Summary
% \section{Summary}
% This CV is automatically generated and deployed using the \href{https://github.com/jitinnair1/autoCV}{autoCV} template along with GitHub Actions such that a new version of the CV is compiled, published and ready for use when the cv.tex file is updated. For details, \href{https://github.com/jitinnair1/autoCV}{click here}.

%Experience

\section{Work Experience}

\begin{tabularx}{\linewidth}{ @{}l r@{} }

\textbf{Research Assistant} & \hfill \textbf{Los Angeles, CA}
\\ {\em USC Ming Hsieh Department of ECE - Data Science Lab} & \hfill {\em January 2023 - Present}\\
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
    \item[--] Develop novel techniques for accelerating deep learning models on specialized hardware accelerators for compute-intensive applications under the supervision of Prof. Viktor Prasanna and Prof. Raj Kannan.
    \item[--] Mentor exchange students on research projects related to high-performance computing and hardware acceleration, providing guidance on problem formulation, algorithm design, and experimental setup.
    % \item[--] Organize and actively participate in weekly group meetings to discuss progress and exchange ideas.
    % \item[--] Present findings at conferences to showcase the lab's work and engage with the broader community.
    \end{itemize}
\end{minipage}
}
\\ \\
\textbf{Undergraduate Research Assistant} & \hfill \textbf{Marina del Rey, CA}
\\{\em USC Information Sciences Institute - STEEL: Security Research Lab} & \hfill {\em May 2022 - January 2023}\\
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
    \begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
    \item[--] Developed scripts to automate the PCA algorithm for detecting energy grid outages in synthetic data.
    \item[--] Performed sentiment analysis on the Enron corpus to train a machine learning model to classify spam.
    \end{itemize}
\end{minipage}
}
\\
\end{tabularx}


%Projects
\section{Projects}
\begin{tabularx}{\linewidth}{ @{}l r@{} }
\textbf{Machine Learning for Data Prefetching} & \hfill {\em Jan. 2023 â€“ Present} \\
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
\begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
\item[--] Develop novel computer architecture approaches to tackle post-Moore's Law memory scaling using ML to better L3 cache utilization compared to traditional rule-based prefetchers.
% \item[--] Compress neural network-based memory access prediction models using knowledge distillation, optimizing them for irregular memory access patterns prevalent in sparse data and graph analytics.
\item[--] Implement the first instance of a practical neural network-based prefetcher with inference latency comparable to rule-based prefetchers by distilling and approximating Transformers using tables.
\end{itemize}
\end{minipage}
}
\\ \\
\textbf{Efficient Table-Based Neural Network} 
& \hfill {\em Jan. 2023 - Present} \\
\multicolumn{2}{@{}X@{}}{
\begin{minipage}[t]{\linewidth}
\begin{itemize}[nosep,after=\strut, leftmargin=1em, itemsep=3pt]
\item[--] Designed primitives for matrix multiplication, convolutions, and multi-headed self-attention that are approximated using a product quantization strategy and can be efficiently looked up in a table.
\item[--] Reduced arithmetic operations during inference by over 90\% for compute-intensive operations.
% \item[--] Developed a comprehensive design methodology and fine-tuning process for training full neural networks based on table-based primitives, using layer-masking and layer-wise table size hyperparameter tuning.
\end{itemize}
\end{minipage}
}
\\
\end{tabularx}

\section{Publications}
\nocite{*}
\printbibliography[heading=none]

\vfill
\center{\footnotesize Last updated: \today}

\end{document}
